{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/otabek5454/net_intrusion_detection/blob/master/model.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t9RGx3hvUJvt",
        "outputId": "be846a16-65c1-4027-e9d0-190251c877cc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/gdown/cli.py:121: FutureWarning: Option `--id` was deprecated in version 4.3.1 and will be removed in 5.0. You don't need to pass it anymore to use a file ID.\n",
            "  warnings.warn(\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1-t3RdDpmqMs4ABt9oobSapeNYTZJ9tpu\n",
            "To: /content/MachineLearningCSV.zip\n",
            "100% 235M/235M [00:04<00:00, 53.3MB/s]\n",
            "Archive:  MachineLearningCSV.zip\n",
            "   creating: MachineLearningCVE/\n",
            "  inflating: MachineLearningCVE/Wednesday-workingHours.pcap_ISCX.csv  \n",
            "  inflating: MachineLearningCVE/Tuesday-WorkingHours.pcap_ISCX.csv  \n",
            "  inflating: MachineLearningCVE/Thursday-WorkingHours-Morning-WebAttacks.pcap_ISCX.csv  \n",
            "  inflating: MachineLearningCVE/Thursday-WorkingHours-Afternoon-Infilteration.pcap_ISCX.csv  \n",
            "  inflating: MachineLearningCVE/Monday-WorkingHours.pcap_ISCX.csv  \n",
            "  inflating: MachineLearningCVE/Friday-WorkingHours-Morning.pcap_ISCX.csv  \n",
            "  inflating: MachineLearningCVE/Friday-WorkingHours-Afternoon-PortScan.pcap_ISCX.csv  \n",
            "  inflating: MachineLearningCVE/Friday-WorkingHours-Afternoon-DDos.pcap_ISCX.csv  \n"
          ]
        }
      ],
      "source": [
        "!gdown --id 1-t3RdDpmqMs4ABt9oobSapeNYTZJ9tpu\n",
        "!unzip MachineLearningCSV.zip"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PeAGjQlZx6ro",
        "outputId": "6e393dfc-9f6e-4b13-fd4d-d2a1803cc798"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2023-07-29 09:43:13--  https://raw.githubusercontent.com/Jumabek/net_intrusion_detection/develop/models.py\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.110.133, 185.199.109.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 15128 (15K) [text/plain]\n",
            "Saving to: ‘models.py’\n",
            "\n",
            "models.py           100%[===================>]  14.77K  --.-KB/s    in 0s      \n",
            "\n",
            "2023-07-29 09:43:13 (143 MB/s) - ‘models.py’ saved [15128/15128]\n",
            "\n",
            "--2023-07-29 09:43:13--  https://raw.githubusercontent.com/Jumabek/net_intrusion_detection/develop/preprocessing.py\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 3790 (3.7K) [text/plain]\n",
            "Saving to: ‘preprocessing.py’\n",
            "\n",
            "preprocessing.py    100%[===================>]   3.70K  --.-KB/s    in 0s      \n",
            "\n",
            "2023-07-29 09:43:13 (82.6 MB/s) - ‘preprocessing.py’ saved [3790/3790]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!wget https://raw.githubusercontent.com/Jumabek/net_intrusion_detection/develop/models.py\n",
        "!wget https://raw.githubusercontent.com/Jumabek/net_intrusion_detection/develop/preprocessing.py"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Jc4d957fw2jH"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "from sklearn.model_selection import train_test_split\n",
        "from preprocessing import load_data, balance_data, normalize\n",
        "from models import Classifier\n",
        "import time\n",
        "from os.path import join\n",
        "from sklearn import metrics\n",
        "from sklearn.metrics import confusion_matrix, classification_report\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import roc_curve, auc\n",
        "from sklearn.preprocessing import label_binarize"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yKOdfcw9k5ie",
        "outputId": "e3cc1a53-7ca4-4517-8be1-cf82c9bd8180"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[########################################] | 100% Completed | 28.19 s\n",
            "[########################################] | 100% Completed | 27.31 s\n",
            "there are 2830743 flow records with 79 feature dimension\n",
            "stripped column names\n",
            "dropped bad columns\n",
            "There are 0 nan entries\n",
            "converted to numeric\n"
          ]
        }
      ],
      "source": [
        "dataroot = 'MachineLearningCVE/'\n",
        "\n",
        "from preprocessing import read_data\n",
        "data = read_data(dataroot,'*.pcap_ISCX.csv')\n",
        "\n",
        "# Load and preprocess the data\n",
        "X, y = load_data(dataroot)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "V7Yug4oANbsn"
      },
      "outputs": [],
      "source": [
        "X, y = balance_data(X, y, seed=42)\n",
        "X = normalize(X)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-4gGvttsxAoI"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Split the data into training and remaining sets first\n",
        "X_temp, X_test, y_temp, y_test = train_test_split(X, y, test_size=0.15, random_state=42)\n",
        "\n",
        "# Split the remaining data into training and validation sets\n",
        "X_train, X_val, y_train, y_val = train_test_split(X_temp, y_temp, test_size=0.176, random_state=42)\n",
        "\n",
        "# Convert the data into PyTorch tensors\n",
        "X_train = torch.tensor(X_train, dtype=torch.float32)\n",
        "y_train = torch.tensor(y_train, dtype=torch.long)\n",
        "\n",
        "X_val = torch.tensor(X_val, dtype=torch.float32)\n",
        "y_val = torch.tensor(y_val, dtype=torch.long)\n",
        "\n",
        "X_test = torch.tensor(X_test, dtype=torch.float32)\n",
        "y_test = torch.tensor(y_test, dtype=torch.long)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7GRaCT-1xGet"
      },
      "outputs": [],
      "source": [
        "# Create PyTorch data loaders\n",
        "batch_size = 32\n",
        "train_data = TensorDataset(X_train, y_train)\n",
        "val_data = TensorDataset(X_val, y_val)\n",
        "train_loader = DataLoader(train_data, batch_size=batch_size, shuffle=True)\n",
        "val_loader = DataLoader(val_data, batch_size=batch_size)\n",
        "\n",
        "device = \"cuda\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6RzKiQtkxHRX"
      },
      "outputs": [],
      "source": [
        "#hyper-parameters\n",
        "hyper_params = {\n",
        "    'batch_size': 5120,\n",
        "    'optim': 'Adam',\n",
        "    'learning_rates': [1e-4, 1e-2, 1e-0],\n",
        "    'regularizations': [1e-6, 1e-4, 1e-2],\n",
        "    'num_layers': 3,\n",
        "    'method': 'softmax',\n",
        "    'num_epochs': 20\n",
        "}\n",
        "\n",
        "# Determine input dimensions and number of classes\n",
        "input_dim = X_train.shape[1]\n",
        "num_class = len(np.unique(y_train))\n",
        "\n",
        "# Initialize tracking variables\n",
        "best_model, best_acc = None, -1\n",
        "accuracies = {}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jhhRMkCjIViR"
      },
      "outputs": [],
      "source": [
        "def getClassifier(args, runs_dir=None):\n",
        "\n",
        "    (method, optim, lr, reg, batch_size, input_dim, num_class, num_epochs) = args\n",
        "    if runs_dir is not None:\n",
        "        ensure_dir(runs_dir)\n",
        "\n",
        "    clf = Classifier(method, input_dim, num_class, lr=lr, reg=reg, num_epochs=num_epochs,\n",
        "                        batch_size=batch_size, runs_dir=runs_dir)\n",
        "\n",
        "    return clf\n",
        "\n",
        "    return clf\n",
        "def ensure_dir(dir_path):\n",
        "    if not os.path.exists(dir_path):\n",
        "        os.makedirs(dir_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BpOeJZxcI6Vc"
      },
      "outputs": [],
      "source": [
        "# Setting up device\n",
        "device = \"cuda\"\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XO1i6UavI-ob"
      },
      "outputs": [],
      "source": [
        "# Convert data types\n",
        "X_train = X_train.float()\n",
        "y_train = y_train.long()\n",
        "\n",
        "# Move data to the device\n",
        "X_train = X_train.to(device)\n",
        "y_train = y_train.to(device)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert the data into numpy arrays\n",
        "X_train, y_train = X_train.cpu().numpy(), y_train.cpu().numpy()\n",
        "X_val, y_val = X_val.cpu().numpy(), y_val.cpu().numpy()\n",
        "X_test, y_test = X_test.cpu().numpy(), y_test.cpu().numpy()\n"
      ],
      "metadata": {
        "id": "NfI20q7vEheY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Grid search over learning rates and regularization strengths\n",
        "for lr in hyper_params['learning_rates']:\n",
        "    for reg in hyper_params['regularizations']:\n",
        "        # Create model configuration\n",
        "        config =  f\"{hyper_params['method']}/train/optim_{hyper_params['num_layers']}_{hyper_params['optim']}_lr_{lr}_reg_{reg}_bs_{hyper_params['batch_size']}\"\n",
        "        runs_dir = join(dataroot, 'runs', config)\n",
        "\n",
        "        # Initialize classifier with current parameters\n",
        "        classifier_args = (hyper_params['method'], hyper_params['optim'], lr, reg, hyper_params['batch_size'], input_dim, num_class, 5)  # Updated to 5 epochs\n",
        "        clf = getClassifier(classifier_args, runs_dir)\n",
        "\n",
        "        # Train and evaluate model\n",
        "        start_time = time.time()\n",
        "        clf.fit(X_train, y_train)\n",
        "        predictions = clf.predict(X_test)\n",
        "        acc = metrics.balanced_accuracy_score(y_test, predictions)\n",
        "\n",
        "        # Update best model if current model is better\n",
        "        if acc > best_acc:\n",
        "            best_model = clf\n",
        "            best_acc = acc\n",
        "\n",
        "        # Store accuracy for current hyper-parameters\n",
        "        accuracies[(lr, reg)] = acc\n",
        "\n",
        "        end_time = time.time()\n",
        "        print(f\"Model trained in {end_time - start_time:.0f} sec\")\n",
        "\n",
        "# Display accuracies\n",
        "print(\"Accuracies for different hyper-parameters:\")\n",
        "for params, acc in accuracies.items():\n",
        "    print(f\"LR: {params[0]}, Reg: {params[1]}, Acc: {acc}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jQSIhSQlHp5T",
        "outputId": "4b54cbc0-05fa-4fd2-f6c8-905c9afafd7b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loaded MachineLearningCVE/runs/softmax/train/optim_3_Adam_lr_0.0001_reg_1e-06_bs_5120 model trained with batch_size = 5120, seen 19 epochs and 368 mini batches\n",
            "best epoch 20, best batch 369\n",
            "bst acc  62.696199056158164\n",
            "Model trained in 17 sec\n",
            "Loaded MachineLearningCVE/runs/softmax/train/optim_3_Adam_lr_0.0001_reg_0.0001_bs_5120 model trained with batch_size = 5120, seen 2 epochs and 1 mini batches\n",
            "best epoch 3, best batch 2\n",
            "bst acc  42.01541034786436\n",
            "Epoch [4/5], Step [3/348], Loss: 2.4347\n",
            "Epoch [4/5], Step [53/348], Loss: 2.4080\n",
            "Epoch [4/5], Step [103/348], Loss: 2.4063\n",
            "Epoch [4/5], Step [153/348], Loss: 2.3779\n",
            "Epoch [4/5], Step [203/348], Loss: 2.3659\n",
            "Epoch [4/5], Step [253/348], Loss: 2.3522\n",
            "Epoch [4/5], Step [303/348], Loss: 2.3252\n",
            "Epoch [5/5], Step [4/348], Loss: 2.3178\n",
            "Epoch [5/5], Step [54/348], Loss: 2.3084\n",
            "Epoch [5/5], Step [104/348], Loss: 2.2945\n",
            "Epoch [5/5], Step [154/348], Loss: 2.2791\n",
            "Epoch [5/5], Step [204/348], Loss: 2.2652\n",
            "Epoch [5/5], Step [254/348], Loss: 2.2483\n",
            "Epoch [5/5], Step [304/348], Loss: 2.2328\n",
            "Model trained in 78 sec\n",
            "best epoch 0, best batch 0\n",
            "bst acc  -1\n",
            "Epoch [1/5], Step [50/348], Loss: 2.6819\n",
            "Epoch [1/5], Step [100/348], Loss: 2.6609\n",
            "Epoch [1/5], Step [150/348], Loss: 2.6423\n",
            "Epoch [1/5], Step [200/348], Loss: 2.6228\n",
            "Epoch [1/5], Step [250/348], Loss: 2.6067\n",
            "Epoch [1/5], Step [300/348], Loss: 2.5894\n",
            "Epoch [2/5], Step [1/348], Loss: 2.5678\n",
            "Epoch [2/5], Step [51/348], Loss: 2.5507\n",
            "Epoch [2/5], Step [101/348], Loss: 2.5258\n",
            "Epoch [2/5], Step [151/348], Loss: 2.5124\n",
            "Epoch [2/5], Step [201/348], Loss: 2.4926\n",
            "Epoch [2/5], Step [251/348], Loss: 2.4839\n",
            "Epoch [2/5], Step [301/348], Loss: 2.4644\n",
            "Epoch [3/5], Step [2/348], Loss: 2.4514\n",
            "Epoch [3/5], Step [52/348], Loss: 2.4313\n",
            "Epoch [3/5], Step [102/348], Loss: 2.4173\n",
            "Epoch [3/5], Step [152/348], Loss: 2.4009\n",
            "Epoch [3/5], Step [202/348], Loss: 2.3828\n",
            "Epoch [3/5], Step [252/348], Loss: 2.3674\n",
            "Epoch [3/5], Step [302/348], Loss: 2.3657\n",
            "Epoch [4/5], Step [3/348], Loss: 2.3462\n",
            "no improvement in accuracy for 10 iterations\n",
            "Model trained in 112 sec\n",
            "best epoch 0, best batch 0\n",
            "bst acc  -1\n",
            "Epoch [1/5], Step [50/348], Loss: 1.6941\n",
            "Epoch [1/5], Step [100/348], Loss: 1.3798\n",
            "Epoch [1/5], Step [150/348], Loss: 1.1861\n",
            "Epoch [1/5], Step [200/348], Loss: 1.0666\n",
            "Epoch [1/5], Step [250/348], Loss: 0.9784\n",
            "Epoch [1/5], Step [300/348], Loss: 0.9322\n",
            "Epoch [2/5], Step [1/348], Loss: 0.8750\n",
            "Epoch [2/5], Step [51/348], Loss: 0.8194\n",
            "Epoch [2/5], Step [101/348], Loss: 0.7870\n",
            "Epoch [2/5], Step [151/348], Loss: 0.7643\n",
            "Epoch [2/5], Step [201/348], Loss: 0.7235\n",
            "Epoch [2/5], Step [251/348], Loss: 0.7159\n",
            "Epoch [2/5], Step [301/348], Loss: 0.6659\n",
            "Epoch [3/5], Step [2/348], Loss: 0.6613\n",
            "Epoch [3/5], Step [52/348], Loss: 0.6302\n",
            "Epoch [3/5], Step [102/348], Loss: 0.6193\n",
            "Epoch [3/5], Step [152/348], Loss: 0.6026\n",
            "Epoch [3/5], Step [202/348], Loss: 0.6042\n",
            "Epoch [3/5], Step [252/348], Loss: 0.5544\n",
            "Epoch [3/5], Step [302/348], Loss: 0.5898\n",
            "Epoch [4/5], Step [3/348], Loss: 0.5829\n",
            "Epoch [4/5], Step [53/348], Loss: 0.5489\n",
            "Epoch [4/5], Step [103/348], Loss: 0.5551\n",
            "Epoch [4/5], Step [153/348], Loss: 0.5434\n",
            "Epoch [4/5], Step [203/348], Loss: 0.5280\n",
            "Epoch [4/5], Step [253/348], Loss: 0.5143\n",
            "Epoch [4/5], Step [303/348], Loss: 0.4951\n",
            "Epoch [5/5], Step [4/348], Loss: 0.5321\n",
            "Epoch [5/5], Step [54/348], Loss: 0.5250\n",
            "Epoch [5/5], Step [104/348], Loss: 0.5155\n",
            "Epoch [5/5], Step [154/348], Loss: 0.4859\n",
            "Epoch [5/5], Step [204/348], Loss: 0.4966\n",
            "Epoch [5/5], Step [254/348], Loss: 0.4831\n",
            "Epoch [5/5], Step [304/348], Loss: 0.4914\n",
            "Model trained in 166 sec\n",
            "best epoch 0, best batch 0\n",
            "bst acc  -1\n",
            "Epoch [1/5], Step [50/348], Loss: 1.6981\n",
            "Epoch [1/5], Step [100/348], Loss: 1.3859\n",
            "Epoch [1/5], Step [150/348], Loss: 1.1963\n",
            "Epoch [1/5], Step [200/348], Loss: 1.0809\n",
            "Epoch [1/5], Step [250/348], Loss: 0.9978\n",
            "Epoch [1/5], Step [300/348], Loss: 0.9591\n",
            "Epoch [2/5], Step [1/348], Loss: 0.9092\n",
            "Epoch [2/5], Step [51/348], Loss: 0.8575\n",
            "Epoch [2/5], Step [101/348], Loss: 0.8331\n",
            "Epoch [2/5], Step [151/348], Loss: 0.8190\n",
            "Epoch [2/5], Step [201/348], Loss: 0.7871\n",
            "Epoch [2/5], Step [251/348], Loss: 0.7907\n",
            "Epoch [2/5], Step [301/348], Loss: 0.7482\n",
            "Epoch [3/5], Step [2/348], Loss: 0.7547\n",
            "Epoch [3/5], Step [52/348], Loss: 0.7265\n",
            "Epoch [3/5], Step [102/348], Loss: 0.7270\n",
            "Epoch [3/5], Step [152/348], Loss: 0.7146\n",
            "Epoch [3/5], Step [202/348], Loss: 0.7242\n",
            "Epoch [3/5], Step [252/348], Loss: 0.6853\n",
            "Epoch [3/5], Step [302/348], Loss: 0.7269\n",
            "Epoch [4/5], Step [3/348], Loss: 0.7244\n",
            "Epoch [4/5], Step [53/348], Loss: 0.6951\n",
            "Epoch [4/5], Step [103/348], Loss: 0.7172\n",
            "Epoch [4/5], Step [153/348], Loss: 0.7009\n",
            "Epoch [4/5], Step [203/348], Loss: 0.6986\n",
            "Epoch [4/5], Step [253/348], Loss: 0.6949\n",
            "Epoch [4/5], Step [303/348], Loss: 0.6713\n",
            "Epoch [5/5], Step [4/348], Loss: 0.7051\n",
            "Epoch [5/5], Step [54/348], Loss: 0.7063\n",
            "Epoch [5/5], Step [104/348], Loss: 0.7083\n",
            "Epoch [5/5], Step [154/348], Loss: 0.6738\n",
            "Epoch [5/5], Step [204/348], Loss: 0.6929\n",
            "Epoch [5/5], Step [254/348], Loss: 0.6836\n",
            "Epoch [5/5], Step [304/348], Loss: 0.6923\n",
            "Model trained in 166 sec\n",
            "best epoch 0, best batch 0\n",
            "bst acc  -1\n",
            "Epoch [1/5], Step [50/348], Loss: 1.8421\n",
            "Epoch [1/5], Step [100/348], Loss: 1.7125\n",
            "Epoch [1/5], Step [150/348], Loss: 1.6708\n",
            "Epoch [1/5], Step [200/348], Loss: 1.6491\n",
            "Epoch [1/5], Step [250/348], Loss: 1.6529\n",
            "Epoch [1/5], Step [300/348], Loss: 1.6666\n",
            "Epoch [2/5], Step [1/348], Loss: 1.6675\n",
            "Epoch [2/5], Step [51/348], Loss: 1.6538\n",
            "Epoch [2/5], Step [101/348], Loss: 1.6444\n",
            "Epoch [2/5], Step [151/348], Loss: 1.6447\n",
            "Epoch [2/5], Step [201/348], Loss: 1.6430\n",
            "Epoch [2/5], Step [251/348], Loss: 1.6686\n",
            "no improvement in accuracy for 10 iterations\n",
            "Model trained in 72 sec\n",
            "best epoch 0, best batch 0\n",
            "bst acc  -1\n",
            "Epoch [1/5], Step [50/348], Loss: 0.5414\n",
            "Epoch [1/5], Step [100/348], Loss: 0.4715\n",
            "Epoch [1/5], Step [150/348], Loss: 0.4427\n",
            "Epoch [1/5], Step [200/348], Loss: 0.4235\n",
            "Epoch [1/5], Step [250/348], Loss: 0.4008\n",
            "Epoch [1/5], Step [300/348], Loss: 0.4074\n",
            "Epoch [2/5], Step [1/348], Loss: 0.4001\n",
            "Epoch [2/5], Step [51/348], Loss: 0.3998\n",
            "Epoch [2/5], Step [101/348], Loss: 0.3926\n",
            "Epoch [2/5], Step [151/348], Loss: 0.3923\n",
            "Epoch [2/5], Step [201/348], Loss: 0.3927\n",
            "Epoch [2/5], Step [251/348], Loss: 0.3873\n",
            "Epoch [2/5], Step [301/348], Loss: 0.3642\n",
            "Epoch [3/5], Step [2/348], Loss: 0.3528\n",
            "Epoch [3/5], Step [52/348], Loss: 0.3589\n",
            "Epoch [3/5], Step [102/348], Loss: 0.3557\n",
            "Epoch [3/5], Step [152/348], Loss: 0.3593\n",
            "Epoch [3/5], Step [202/348], Loss: 0.3958\n",
            "Epoch [3/5], Step [252/348], Loss: 0.3393\n",
            "Epoch [3/5], Step [302/348], Loss: 0.3641\n",
            "Epoch [4/5], Step [3/348], Loss: 0.3991\n",
            "Epoch [4/5], Step [53/348], Loss: 0.3641\n",
            "Epoch [4/5], Step [103/348], Loss: 0.3594\n",
            "Epoch [4/5], Step [153/348], Loss: 0.3673\n",
            "Epoch [4/5], Step [203/348], Loss: 0.3377\n",
            "Epoch [4/5], Step [253/348], Loss: 0.3436\n",
            "Epoch [4/5], Step [303/348], Loss: 0.3208\n",
            "Epoch [5/5], Step [4/348], Loss: 0.3631\n",
            "Epoch [5/5], Step [54/348], Loss: 0.3733\n",
            "Epoch [5/5], Step [104/348], Loss: 0.3690\n",
            "Epoch [5/5], Step [154/348], Loss: 0.3247\n",
            "Epoch [5/5], Step [204/348], Loss: 0.3525\n",
            "Epoch [5/5], Step [254/348], Loss: 0.3617\n",
            "Epoch [5/5], Step [304/348], Loss: 0.3417\n",
            "Model trained in 167 sec\n",
            "best epoch 0, best batch 0\n",
            "bst acc  -1\n",
            "Epoch [1/5], Step [50/348], Loss: 0.7238\n",
            "Epoch [1/5], Step [100/348], Loss: 0.7127\n",
            "Epoch [1/5], Step [150/348], Loss: 0.6996\n",
            "Epoch [1/5], Step [200/348], Loss: 0.7183\n",
            "Epoch [1/5], Step [250/348], Loss: 0.6881\n",
            "Epoch [1/5], Step [300/348], Loss: 0.7052\n",
            "Epoch [2/5], Step [1/348], Loss: 0.7186\n",
            "Epoch [2/5], Step [51/348], Loss: 0.6960\n",
            "Epoch [2/5], Step [101/348], Loss: 0.7015\n",
            "Epoch [2/5], Step [151/348], Loss: 0.7097\n",
            "Epoch [2/5], Step [201/348], Loss: 0.7044\n",
            "Epoch [2/5], Step [251/348], Loss: 0.7216\n",
            "Epoch [2/5], Step [301/348], Loss: 0.6930\n",
            "Epoch [3/5], Step [2/348], Loss: 0.7058\n",
            "Epoch [3/5], Step [52/348], Loss: 0.6894\n",
            "Epoch [3/5], Step [102/348], Loss: 0.7121\n",
            "Epoch [3/5], Step [152/348], Loss: 0.6949\n",
            "Epoch [3/5], Step [202/348], Loss: 0.7194\n",
            "Epoch [3/5], Step [252/348], Loss: 0.6693\n",
            "Epoch [3/5], Step [302/348], Loss: 0.7089\n",
            "Epoch [4/5], Step [3/348], Loss: 0.7569\n",
            "Epoch [4/5], Step [53/348], Loss: 0.6853\n",
            "Epoch [4/5], Step [103/348], Loss: 0.7056\n",
            "Epoch [4/5], Step [153/348], Loss: 0.6947\n",
            "Epoch [4/5], Step [203/348], Loss: 0.6947\n",
            "no improvement in accuracy for 10 iterations\n",
            "Model trained in 128 sec\n",
            "best epoch 0, best batch 0\n",
            "bst acc  -1\n",
            "Epoch [1/5], Step [50/348], Loss: 1.6719\n",
            "Epoch [1/5], Step [100/348], Loss: 1.6813\n",
            "Epoch [1/5], Step [150/348], Loss: 1.6731\n",
            "Epoch [1/5], Step [200/348], Loss: 1.6620\n",
            "Epoch [1/5], Step [250/348], Loss: 1.6661\n",
            "Epoch [1/5], Step [300/348], Loss: 1.6944\n",
            "Epoch [2/5], Step [1/348], Loss: 1.6877\n",
            "Epoch [2/5], Step [51/348], Loss: 1.6662\n",
            "Epoch [2/5], Step [101/348], Loss: 1.6545\n",
            "Epoch [2/5], Step [151/348], Loss: 1.6680\n",
            "Epoch [2/5], Step [201/348], Loss: 1.6873\n",
            "Epoch [2/5], Step [251/348], Loss: 1.6897\n",
            "Epoch [2/5], Step [301/348], Loss: 1.6891\n",
            "Epoch [3/5], Step [2/348], Loss: 1.7000\n",
            "no improvement in accuracy for 10 iterations\n",
            "Model trained in 81 sec\n",
            "Accuracies for different hyper-parameters:\n",
            "LR: 0.0001, Reg: 1e-06, Acc: 0.6273938354329425\n",
            "LR: 0.0001, Reg: 0.0001, Acc: 0.4790231351753545\n",
            "LR: 0.0001, Reg: 0.01, Acc: 0.4837523047357489\n",
            "LR: 0.01, Reg: 1e-06, Acc: 0.8339640297160034\n",
            "LR: 0.01, Reg: 0.0001, Acc: 0.7933094817473031\n",
            "LR: 0.01, Reg: 0.01, Acc: 0.5795583646626756\n",
            "LR: 1.0, Reg: 1e-06, Acc: 0.8600979484563726\n",
            "LR: 1.0, Reg: 0.0001, Acc: 0.7366698825945347\n",
            "LR: 1.0, Reg: 0.01, Acc: 0.5234609876075517\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "cq_G5eQtL7ir"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "machine_shape": "hm",
      "provenance": [],
      "authorship_tag": "ABX9TyNH/QFiisjcm7eLKE4dol91",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}